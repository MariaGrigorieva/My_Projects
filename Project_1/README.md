# Project_toxic_text

**Описание проекта:**
Разработка модели для классификации комментариев на позитивные и негативные с целью выявлять токсичные комментарии и отправлять их на модерацию.

Задача: обучить модель классифицировать комментарии на позитивные и негативные на основании набора данных с разметкой о токсичности правок, метрика качества F1 модели должна быть не меньше 0.75.

*План проекта:*
- Загрузка и подготовка данных
- Обучение разных моделей
- Выводы

**Выводы по проекту:**

Данные для обучения моделей обработаны:

- проведена лемматизация текста и работа с регулярными выражениями;
- выполнена оценка важности слов величиной TF-IDF.

Обучены несколько моделей с различными гиперпараметрами: LogisticRegression, CatBoostClassifier. Метрика качества выбрана F1.

Наилучший результат показала модель LogisticRegression c подбором порога: Threshold=0.620, F1-Score=0.85766. На тестовых данных модель показала следующие результаты: лучшая метрика F1-Score=0.78215 для порога, равного 0.675.


**Используемые инструменты:** Pandas, nltk, tf-idf
